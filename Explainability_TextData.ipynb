{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d73ca05e",
   "metadata": {},
   "source": [
    "# Explanations in AI: Methods, Stakeholders and Pitfalls\n",
    "<h3 align=\"center\">Text Data</h3>\n",
    "<br>\n",
    "\n",
    "\n",
    "---\n",
    "This notebook shows how to use a pre-trained text classifier to predict the sentiment of movie reviews and how to generate explanations for these predictions using different methods.\n",
    "\n",
    "---\n",
    "__Dataset:__ \n",
    "The [IMDB movie review dataset](https://huggingface.co/datasets/imdb) is a collection of 50,000 movie reviews that were collected from the Internet Movie Database (IMDb). The reviews are labeled as either positive or negative, and they are all associated with a specific movie. The dataset was created by Maas et al. (2011) and is publicly available.\n",
    "\n",
    "---\n",
    "<a name=\"0\">__Contents of Notebook:__</a>\n",
    "\n",
    "1. <a href=\"#1\">Downloading the Dataset</a>\n",
    "2. <a href=\"#2\">Loading and Inspecting the Model</a>\n",
    "3. <a href=\"#3\">Explanations</a> <br>\n",
    "    3.1. <a href=\"#31\">Kernel SHAP</a> <br>\n",
    "    3.2. <a href=\"#32\">Integrated Gradients</a> <br>\n",
    "4. <a href=\"#4\">Potential Issues</a>\n",
    "\n",
    "---\n",
    "Attribution: Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts. 2011. Learning Word Vectors for Sentiment Analysis. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics.\n",
    "\n",
    "This notebook uses modified code snippets from [Captum](https://captum.ai/) and [HuggingFace](huggingface.co/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be5925d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operational libraries\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Jupyter(lab) libraries\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Reshaping/basic libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# Neural Net libraries\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "import tensorflow as tf\n",
    "\n",
    "# Globals\n",
    "import logging\n",
    "\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "\n",
    "# Explainability libraries\n",
    "import captum\n",
    "from captum.attr import visualization\n",
    "\n",
    "# Helper libraries\n",
    "from IPython.display import display, HTML\n",
    "import datasets\n",
    "\n",
    "# Store pretrained models and datasets\n",
    "cache_dir = Path(\".cache\")\n",
    "cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "set_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c21545",
   "metadata": {},
   "source": [
    "## 1. <a name=\"1\">Downloading the Dataset</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "Let's download and unpack the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb49694",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# load the dataset\n",
    "dataset = datasets.load_dataset(\"imdb\", cache_dir=cache_dir/\"datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee12bca5",
   "metadata": {},
   "source": [
    "## 2. <a name=\"2\">Loading and Inspecting the Model</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "Let's read in the dataset and inspect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed6c59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add mapping from label class to true sentiment\n",
    "label_to_sentiment = {0: \"Negative\", 1: \"Positive\"}\n",
    "\n",
    "\n",
    "# create helper function to display example instances, labels (and predictions)\n",
    "def display_instance_with_label(\n",
    "    input_text: str, true_label: int, *, pred_label: int = None, pred_prob: float = None\n",
    "):\n",
    "    instance_html = (\n",
    "        f\"<b>Ground Truth Sentiment:</b> {label_to_sentiment[true_label]}<br><br>\"\n",
    "    )\n",
    "    if pred_label is not None:\n",
    "        pred_str = label_to_sentiment[pred_label]\n",
    "        if pred_prob is not None:\n",
    "            pred_str = f\"{pred_str} (Probability: {pred_prob:0.2f})\"\n",
    "        instance_html += f\"<b>Predicted Sentiment:</b> {pred_str}<br><br>\"\n",
    "    instance_html += f\"<b>Review Text:</b> {input_text}\"\n",
    "    instance_html = f\"<pre>{instance_html}</pre>\"\n",
    "    display(HTML(instance_html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce59295",
   "metadata": {},
   "source": [
    "Let us inspect an input. Go ahead and select different inputs to show the text and the sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cad2757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify index from dataset to inspect\n",
    "idx_to_inspect = 99\n",
    "\n",
    "# load the example based on index\n",
    "instance = dataset[\"train\"][idx_to_inspect]\n",
    "\n",
    "# show the example review and sentiment\n",
    "display_instance_with_label(instance[\"text\"], instance[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354f5310",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63c1601",
   "metadata": {},
   "source": [
    "We will use a model trained as a part of [this sequence classification tutorial](https://huggingface.co/docs/transformers/main/tasks/sequence_classification) on HuggingFace. The tutorial takes a `distilbert-base-uncased` pre-trained model and fine-tunes it to IMDB sentiment classification task.\n",
    "\n",
    "\n",
    "If you want to train / fine-tune your own model, follow the instructions in the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31977d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# specify model name to load from HuggingFace\n",
    "model_name = \"stevhliu/my_awesome_model\"\n",
    "\n",
    "# instantiate model\n",
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, cache_dir = cache_dir / \"models\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152246de",
   "metadata": {},
   "source": [
    "Before we start interacting with the model, we also need to load the _tokenizer_ associated with this model. You might wonder what the role of the tokenizer is.\n",
    "\n",
    "The tokenizer converts any input text to features, aka tokens, that the model can recognize. This operation is done by breaking the input words down into sub-words. Let us take an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007ff77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# convert text to tokens\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    model_name, cache_dir = cache_dir / \"models\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa3d271",
   "metadata": {},
   "source": [
    "Let us inspect a couple of examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01940ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample sentence\n",
    "text1 = \"What is amortization\"\n",
    "text2 = \"This is quantization\"\n",
    "\n",
    "# apply tokenization\n",
    "tokens1 = tokenizer.tokenize(text1)\n",
    "tokens2 = tokenizer.tokenize(text2)\n",
    "\n",
    "# show output\n",
    "print(f\"{text1:30} -> {tokens1}\")\n",
    "print(f\"{text2:30} -> {tokens2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3611606",
   "metadata": {},
   "source": [
    "Notice how the tokenizer breaks large words into same tokens `ti` and `zation`.\n",
    "\n",
    "For convenience, each token is mapped onto an numbered ID. You can read more about tokenization [here](https://huggingface.co/docs/transformers/main/preprocessing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c4ac1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each token is assigned an ID, show IDs for tokens\n",
    "tokenizer.convert_tokens_to_ids(tokens1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90510f8e",
   "metadata": {},
   "source": [
    "Now, let us pass a real input through the model. The process is as follows: We will tokenize the input text into tokens (and an attention mask, which you can read about [here](https://huggingface.co/docs/transformers/glossary#attention-mask)). These token IDs get converted into embeddings by the model which then get translated into a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723003a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_logit_from_token_ids(input_ids):\n",
    "    \"\"\"Given the input IDs, get the model output logits\"\"\"\n",
    "    with torch.no_grad():\n",
    "        return model(input_ids=input_ids).logits\n",
    "\n",
    "\n",
    "def get_pred_score_prob_from_input_ids(input_ids):\n",
    "    \"\"\"Given the input IDs, get the model prediction and the predicted probability\"\"\"\n",
    "    # pass tokens (as IDs) to model to get prediction\n",
    "    pred_score = pred_logit_from_token_ids(input_ids).flatten()\n",
    "    # get probability for negative/positive sentiment\n",
    "    pred_class_idx = pred_score.argmax(axis=-1).item()\n",
    "    # compute the softmax probability\n",
    "    pred_prob = F.softmax(pred_score[pred_class_idx])\n",
    "    return pred_class_idx, pred_prob\n",
    "\n",
    "\n",
    "def display_instance_pred_from_token_ids(input_ids):\n",
    "    \"\"\"Given input IDs, display the input text and the model output\"\"\"\n",
    "\n",
    "    pred_class_idx, pred_prob = get_pred_score_prob_from_input_ids(input_ids)\n",
    "\n",
    "    # The tokenizer might cut the text to fit within the model's limit and additionaly\n",
    "    # add special tokens to it. So let us obtain the text that the model sees\n",
    "    tokenized_text = tokenizer.decode(input_ids.flatten())\n",
    "\n",
    "    display_instance_with_label(\n",
    "        tokenized_text,\n",
    "        instance[\"label\"],\n",
    "        pred_label=pred_class_idx,\n",
    "        pred_prob=pred_prob,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fed0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick another sample instance\n",
    "instance = dataset[\"test\"][0]\n",
    "\n",
    "# tokenize instance, this will give IDs and an attention mask\n",
    "input_tokenized = tokenizer(instance[\"text\"], return_tensors=\"pt\")\n",
    "\n",
    "# proceed with the IDs\n",
    "input_ids = input_tokenized[\"input_ids\"]\n",
    "\n",
    "# Display the model input and output\n",
    "display_instance_pred_from_token_ids(input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756c6c0b",
   "metadata": {},
   "source": [
    "## 3. <a name=\"3\">Explanations</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "We will now generate explanations with various methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e326b8db",
   "metadata": {},
   "source": [
    "### 3.1. <a name=\"31\">Kernel SHAP</a>\n",
    "(<a href=\"#3\">Go to Explanations</a>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d4b517",
   "metadata": {},
   "source": [
    "Similar to the tabular data, we have to set a `baseline` which mimics absence of information. Recall that SHAP works by removing different combinations of features (tokens in this case) at a time and monitoring the effect on the model output. We will simulate the removal of a token by replacing it with the baseline token. We set this baseline to the \"unknown token ID\" (`tokenizer.unk_token_id`), which is a default token used when the model encounters a token that is not contained in its vocabulary. You could select other baselines as well. For a discussion into baselines, see [section 5 in this paper](https://arxiv.org/pdf/2106.00786.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16857b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parallelism to 'false' to avoid warnings\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aa5596",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class_idx, pred_prob = get_pred_score_prob_from_input_ids(input_ids)\n",
    "baseline_token = tokenizer.unk_token_id\n",
    "n_samples = 200  # try higher values and monitor how much the results vary\n",
    "perturbations_per_eval = 32\n",
    "ks = captum.attr.KernelShap(pred_logit_from_token_ids)\n",
    "\n",
    "set_seed(1)\n",
    "attrs = ks.attribute(\n",
    "    inputs=input_ids,\n",
    "    baselines=torch.full_like(input_ids, fill_value=tokenizer.unk_token_id),\n",
    "    target=pred_class_idx,\n",
    "    n_samples=n_samples,\n",
    "    perturbations_per_eval=perturbations_per_eval,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6584543",
   "metadata": {},
   "source": [
    "Now, let us visualize the explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7523542",
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs = attrs.flatten()\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids.flatten())\n",
    "viz_data = visualization.VisualizationDataRecord(\n",
    "    word_attributions=attrs,\n",
    "    pred_prob=pred_prob,\n",
    "    pred_class=label_to_sentiment[pred_class_idx],\n",
    "    true_class=label_to_sentiment[instance[\"label\"]],\n",
    "    attr_class=label_to_sentiment[pred_class_idx],\n",
    "    attr_score=attrs.sum(),\n",
    "    raw_input_ids=tokens,\n",
    "    convergence_score=0,  # Captum KernelSHAP does not provide this info.\n",
    ")\n",
    "visualization.visualize_text([viz_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c471068",
   "metadata": {},
   "source": [
    "### 3.2. <a name=\"32\">Integrated Gradients</a>\n",
    "(<a href=\"#3\">Go to Explanations</a>)\n",
    "\n",
    "We can also use the Integrated Gradients explainer. Recall from our Tabular data notebook that this method involves taking the gradient of the model output w.r.t. inputs. Since we cannot compute gradients w.r.t. the input tokens (due to the discreet step where tokens are mapped to input embeddings), we will take the gradients w.r.t. the input embeddings. For details on how the tokens are mapped into input embeddings, see Figure 2 in the [BERT paper](https://arxiv.org/pdf/1810.04805.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfc6f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_logit_from_embeddings(embeds):\n",
    "    return model(inputs_embeds=embeds).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aef9f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_embeds = model.distilbert.embeddings(input_ids=input_ids)\n",
    "baseline = model.distilbert.embeddings(\n",
    "    input_ids=torch.full_like(input_ids, fill_value=tokenizer.unk_token_id)\n",
    ")\n",
    "n_steps = 10\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "ig = captum.attr.IntegratedGradients(pred_logit_from_embeddings)\n",
    "\n",
    "attrs, convergence_delta = ig.attribute(\n",
    "    inputs=inputs_embeds,\n",
    "    baselines=baseline,\n",
    "    target=pred_class_idx,\n",
    "    n_steps=n_steps,\n",
    "    return_convergence_delta=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03a8286",
   "metadata": {},
   "source": [
    "The embedding corresponding to each token is a 768 dimensional vector. Which means that each token has 768 importance scores. We sum these scores to get a single scalar importance score per token. You could also use other options like $L2$-norm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46899a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs = attrs.sum(dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2fb293",
   "metadata": {},
   "source": [
    "Let us visualize the importance scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43015565",
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs = attrs.flatten()\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids.flatten())\n",
    "viz_data = visualization.VisualizationDataRecord(\n",
    "    word_attributions=attrs,\n",
    "    pred_prob=pred_prob,\n",
    "    pred_class=label_to_sentiment[pred_class_idx],\n",
    "    true_class=label_to_sentiment[instance[\"label\"]],\n",
    "    attr_class=label_to_sentiment[pred_class_idx],\n",
    "    attr_score=attrs.sum(),\n",
    "    raw_input_ids=tokens,\n",
    "    convergence_score=0,  # Captum KernelSHAP does not provide this info.\n",
    ")\n",
    "visualization.visualize_text([viz_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b5235c",
   "metadata": {},
   "source": [
    "## 4. <a name=\"4\">Potential issues</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "Text explanations also suffer from issues similar to what we faced in Tabular and Image datasets. For instance, randomly initialized models might have explanations that are very similar to those of a trained model (see [On the Lack of Robust Interpretability of Neural Text Classifiers](https://arxiv.org/pdf/2106.04631.pdf)). Removing unimportant features may result in gibberish inputs that the models are very confident about (see [Pathologies of Neural Models Make Interpretations Difficult](https://aclanthology.org/D18-1407.pdf)). Similarly, [The Out-of-Distribution Problem in Explainability and Search Methods for Feature Importance Explanations](https://arxiv.org/abs/2106.00786) show that the feature replacement mechanism that explainers like SHAP use can result in out-of-distribution inputs where the model outputs are unreliable. This in turn could impact the utility of explanations. \n",
    "\n",
    "To get a quick insight into these issues, let us compare the model output on an input and its perturbed version.\n",
    "\n",
    "First, we print the model output on the original input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3accaa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = dataset[\"test\"][0]\n",
    "input_tokenized = tokenizer(instance[\"text\"], return_tensors=\"pt\")\n",
    "input_ids = input_tokenized[\"input_ids\"]\n",
    "display_instance_pred_from_token_ids(input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575ba837",
   "metadata": {},
   "source": [
    "Now, let us select a random subset of 50% tokens with `unknown` token. We do this replacement to mimic the perturbations made by explainers like SHAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb423cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(1)\n",
    "idx_replace = np.random.permutation(input_ids.shape[1])[: input_ids.shape[1] // 2]\n",
    "perturbed_input_ids = input_ids.clone()\n",
    "perturbed_input_ids[:, idx_replace] = tokenizer.unk_token_id\n",
    "display_instance_pred_from_token_ids(perturbed_input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779de381",
   "metadata": {},
   "source": [
    "While the text looks unreadable to human eye, the model is still quite confident about its sentiment.\n",
    "\n",
    "Papers like [The Out-of-Distribution Problem in Explainability and Search Methods for Feature Importance Explanations](https://arxiv.org/abs/2106.00786) and [A Benchmark for Interpretability Methods in Deep Neural Networks](https://arxiv.org/pdf/1806.10758.pdf) argue that this out-of-distribution behavior could impact the utility of explanations. Others like [True to the Model or True to the Data?](https://arxiv.org/pdf/2006.16234.pdf) argue that the utility depends on exactly what we are trying to explain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308ca208",
   "metadata": {},
   "source": [
    "## Thank you for participating!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kdd",
   "language": "python",
   "name": "kdd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
