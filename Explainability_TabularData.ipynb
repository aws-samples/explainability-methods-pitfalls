{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanations in AI: Methods, Stakeholders and Pitfalls\n",
    "<h3 align=\"center\">Tabular Data</h3>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "This notebook shows how to build a classifier to predict whether an individuals' loan application will be approved or denied. In more detail: The goal is to predict if the applicant will repay the loan, given an instance of a loan application. To answer this, we will train ML models and explore different techniques to explain these models. \n",
    "\n",
    "---\n",
    "\n",
    "__Dataset:__ \n",
    "We will use the [South German Credit dataset](https://archive.ics.uci.edu/ml/datasets/South+German+Credit+%28UPDATE%29) which classifies whether credit contracts have been complied with (1: good) or not (0: bad) by using a set of attributes. The attributes consist of a mix of categorical, boolean and numerical values. Missing values are denoted as N/A. \n",
    "\n",
    "---\n",
    "\n",
    "<a name=\"0\">__Contents of Notebook:__</a>\n",
    "\n",
    "1. <a href=\"#1\">Download & Read the dataset</a>\n",
    "2. <a href=\"#2\">Data Processing</a>\n",
    "    * <a href=\"#21\">Exploratory Data Analysis</a>\n",
    "    * <a href=\"#22\">Train - Validation - Test Datasets</a>\n",
    "    * <a href=\"#23\">Data processing with Pipeline and ColumnTransformer</a>\n",
    "3. <a href=\"#3\">Train a Classifier</a>\n",
    "    * <a href=\"#31\">Sklearn</a>\n",
    "    * <a href=\"#32\">PyTorch</a>\n",
    "4. <a href=\"#4\">Test the Classifier</a>\n",
    "    * <a href=\"#41\">Sklearn</a>\n",
    "    * <a href=\"#42\">PyTorch</a>\n",
    "5.  <a href=\"#5\">Explanations</a>\n",
    "    * <a href=\"#51\">SHAP Values</a>\n",
    "    * <a href=\"#52\">Counterfactual Explanations</a>\n",
    "    * <a href=\"#53\">Integrated Gradients</a>\n",
    "    * <a href=\"#54\">Influential Instances</a>\n",
    "\n",
    "---\n",
    "Attribution: Dua, D. and Graff, C. (2019). UCI Machine Learning Repository [[http://archive.ics.uci.edu/ml](http://archive.ics.uci.edu/ml)]. Irvine, CA: University of California, School of Information and Computer Science. Grömping, U. (2019). South German Credit Data: Correcting a Widely Used Data Set. Report 4/2019, Reports in Mathematics, Physics and Chemistry, Department II, Beuth University of Applied Sciences Berlin.\n",
    "\n",
    "This notebook uses modified code snippets from [Captum](https://captum.ai/tutorials/Titanic_Basic_Interpret)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T12:02:29.575329Z",
     "start_time": "2023-07-20T12:02:24.587274Z"
    }
   },
   "outputs": [],
   "source": [
    "# Operational libraries\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "# Jupyter(lab) libraries\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Reshaping/basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "plt.style.use(\"seaborn-colorblind\")\n",
    "from utils.gen_utils import extract_mapping\n",
    "from utils.viz_utils import plot_boundary_with_ce\n",
    "\n",
    "# Set the style of plotting to white\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score, confusion_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Explainability libraries\n",
    "import shap\n",
    "from shap import maskers\n",
    "import dice_ml\n",
    "from captum.attr import IntegratedGradients\n",
    "\n",
    "# Load JS visualization code to notebook\n",
    "shap.initjs()\n",
    "\n",
    "# Neural Net libraries\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. <a name=\"1\">Download & Read the dataset</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "Let's download and unpack the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"SouthGermanCredit\")\n",
    "data_dir.mkdir(exist_ok=True, parents=True)\n",
    "compressed_file = data_dir / \"SouthGermanCredit.zip\"\n",
    "if not compressed_file.is_file():\n",
    "    urllib.request.urlretrieve(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/00573/SouthGermanCredit.zip\",\n",
    "        compressed_file,\n",
    "    )\n",
    "with zipfile.ZipFile(compressed_file, \"r\") as f:\n",
    "    f.extractall(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T12:02:29.585969Z",
     "start_time": "2023-07-20T12:02:29.583440Z"
    }
   },
   "outputs": [],
   "source": [
    "# open data dictionary and extract feature names\n",
    "with open(\"codetable.txt\", \"r\") as file:\n",
    "    data = file.read()\n",
    "\n",
    "# extract mapping from data dictionary\n",
    "features_dict, header_dict = extract_mapping(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read in the dataset and rename the column headers to English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T12:02:29.591946Z",
     "start_time": "2023-07-20T12:02:29.586781Z"
    }
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "df = pd.read_csv(data_dir / \"SouthGermanCredit.asc\", sep=\" \")\n",
    "\n",
    "# rename features\n",
    "df.rename(columns=header_dict, inplace=True)\n",
    "\n",
    "# rename target\n",
    "df.rename({\"credit_risk\": \"complied_with_credit_contract\"}, axis=1, inplace=True)\n",
    "\n",
    "# create age group variable and drop age feature\n",
    "df[\"age_groups\"] = df[\"age\"].apply(lambda x: 1 if x >= 25 else 0)\n",
    "df.drop(\"age\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. <a name=\"2\">Data Processing</a>\n",
    "(<a href=\"#0\">Go to top</a>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 <a name=\"21\">Exploratory Data Analysis</a>\n",
    "(<a href=\"#2\">Go to Data Processing</a>)\n",
    "\n",
    "We look at number of rows, columns, and some simple statistics of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T12:02:29.599150Z",
     "start_time": "2023-07-20T12:02:29.592840Z"
    }
   },
   "outputs": [],
   "source": [
    "# print the first few rows\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T12:02:29.630867Z",
     "start_time": "2023-07-20T12:02:29.599494Z"
    }
   },
   "outputs": [],
   "source": [
    "# check how many rows and columns we have in the data frame\n",
    "print(\"The shape of the dataset is:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T12:02:29.631218Z",
     "start_time": "2023-07-20T12:02:29.604761Z"
    }
   },
   "outputs": [],
   "source": [
    "# let's see the data types and non-null values for each column\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation\n",
    "\n",
    "Based on the feature names, we can see that we are dealing with multimodal data: a mix of categorical, numerical and boolean values. Let's start by creating list for each feature type. If it looks good, we can separate model features from model target to explore them separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T12:02:29.631316Z",
     "start_time": "2023-07-20T12:02:29.608562Z"
    }
   },
   "outputs": [],
   "source": [
    "# identify the model target\n",
    "model_target = \"complied_with_credit_contract\"\n",
    "\n",
    "# remaining features are numerical\n",
    "numerical_features = [\n",
    "    \"amount\",\n",
    "    \"duration\",\n",
    "]\n",
    "\n",
    "# split based on categorical nominal and ordinal\n",
    "categorical_features_nominal = [\n",
    "    \"age_groups\",\n",
    "    \"credit_history\",\n",
    "    \"foreign_worker\",\n",
    "    \"housing\",\n",
    "    \"other_debtors\",\n",
    "    \"other_installment_plans\",\n",
    "    \"people_liable\",\n",
    "    \"personal_status_sex\",\n",
    "    \"purpose\",\n",
    "    \"savings\",\n",
    "    \"status\",\n",
    "    \"telephone\",\n",
    "]\n",
    "\n",
    "categorical_features_ordinal = [\n",
    "    \"employment_duration\",\n",
    "    \"installment_rate\",\n",
    "    \"job\",\n",
    "    \"number_credits\",\n",
    "    \"present_residence\",\n",
    "    \"property\",\n",
    "]\n",
    "\n",
    "# map numerical values in dataset to underlying categories\n",
    "for col in categorical_features_nominal:\n",
    "    if col != \"age_groups\":\n",
    "        df[col] = df[col].apply(lambda x: features_dict[col][x])\n",
    "    else:\n",
    "        df[col] = df[col].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up some additional lists that can be reused later for visualizations and model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the categorical features for further analysis\n",
    "categorical_features = categorical_features_nominal + categorical_features_ordinal\n",
    "\n",
    "# assign model features\n",
    "model_features = categorical_features + numerical_features\n",
    "\n",
    "# print the features and target\n",
    "print(\"Model features: \", model_features)\n",
    "print(\"Model target: \", model_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T12:02:29.648832Z",
     "start_time": "2023-07-20T12:02:29.623600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Double check that that target is not accidentally part of the features\n",
    "model_target in model_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All good here. We made sure that the target is not in the feature list. If we find the above statement showing `True` we need to remove the target by calling `model_features.remove(model_target)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target distribution\n",
    "\n",
    "Let's check our target distribution. This is the most important column to analyze. We need to check the distribution of the target as well as any skew towards different subpopulations. Eventually we want to compare quality of explanations for two subgroups in the dataset (age $\\geq$ 25 and age <25 years old)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T12:02:29.821856Z",
     "start_time": "2023-07-20T12:02:29.626846Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# plot target again but split by age group\n",
    "g = sns.catplot(\n",
    "    x=model_target,\n",
    "    kind=\"count\",\n",
    "    hue=\"age_groups\",\n",
    "    data=df,\n",
    "    palette=\"husl\",\n",
    "    legend=False,\n",
    ")\n",
    "\n",
    "g.fig.set_size_inches(8, 4)\n",
    "plt.title(\"Histogram of outcomes (split by age group)\")\n",
    "plt.legend(title=\"age_groups\", loc=\"upper left\", labels=[\"<25y\", \">=25y\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that we are dealing with an imbalanced dataset; there are more examples for one class 1. Interestingly, the average default rate on loans in Germany at the time the dataset was collected was approximately 5 percent. As the target distribution shows a much larger percentage of individuals that did not comply with the credit contract, we can assume that intentional oversampling of the negative class was conducted to better identify individuals who are likely to default. \n",
    "\n",
    "In addition, as we split the plot based on age groups we can also observe the following:\n",
    "- There is only a small fraction of applications from individuals <25y old.\n",
    "- For the age group <25y the outcome is split at almost 50/50; this could indicate that there is bias present in the data or point at sampling issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 <a name=\"22\">Train - Validation - Test Datasets</a>\n",
    "(<a href=\"#2\">Go to Data Processing</a>)\n",
    "\n",
    "Following general best practice for building Machine Learning models, we want to split our data into train, test and validation set. To obtain these splits, we will use sklearn's [train_test_split()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T12:02:29.822158Z",
     "start_time": "2023-07-20T12:02:29.766222Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(\n",
    "    df, test_size=0.1, shuffle=True, random_state=23\n",
    ")\n",
    "train_data, val_data = train_test_split(\n",
    "    train_data, test_size=0.15, shuffle=True, random_state=23\n",
    ")\n",
    "\n",
    "# Print the shapes of the Train - Test Datasets\n",
    "print(\n",
    "    \"Train - Test - Validation datasets shapes: \",\n",
    "    train_data.shape,\n",
    "    test_data.shape,\n",
    "    val_data.shape,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 <a name=\"23\">Data processing with Pipeline and ColumnTransformer</a>\n",
    "(<a href=\"#2\">Go to Data Processing</a>)\n",
    "\n",
    "Let's build a full model pipeline. We need pre-processing split per data type, and then combine everything back into a composite pipeline so that we can transform all features once and for all and then build different models on top. To achieve the desired data prep, we will use sklearns `Pipeline` and `ColumnTransformer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T12:02:40.907579Z",
     "start_time": "2023-07-20T12:02:40.862387Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocess the numerical features\n",
    "numerical_processor = Pipeline(\n",
    "    [\n",
    "        (\"num_imputer\", SimpleImputer(strategy=\"mean\", add_indicator=True)),\n",
    "        (\"num_scaler\", MinMaxScaler()),\n",
    "    ]\n",
    ")\n",
    "# Preprocess the categorical features\n",
    "categorical_processor_nominal = Pipeline(\n",
    "    [\n",
    "        (\"cat_imputer\", SimpleImputer(strategy=\"constant\")),\n",
    "        (\"cat_encoder_nom\", OneHotEncoder(handle_unknown=\"ignore\", drop=\"if_binary\")),\n",
    "    ]\n",
    ")\n",
    "categorical_processor_ordinal = Pipeline(\n",
    "    [\n",
    "        (\"cat_imputer\", SimpleImputer(strategy=\"constant\")),\n",
    "        (\n",
    "            \"cat_encoder_ord\",\n",
    "            OrdinalEncoder(handle_unknown=\"error\"),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Combine all data pre-processors from above\n",
    "data_processor = ColumnTransformer(\n",
    "    [\n",
    "        (\"numerical_processing\", numerical_processor, numerical_features),\n",
    "        (\n",
    "            \"categorical_processing_nom\",\n",
    "            categorical_processor_nominal,\n",
    "            categorical_features_nominal,\n",
    "        ),\n",
    "        (\n",
    "            \"categorical_processing_ord\",\n",
    "            categorical_processor_ordinal,\n",
    "            categorical_features_ordinal,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Pipeline with desired data transformers, along with an estimator at the end\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"data_processing\", data_processor),\n",
    "        (\"rf\", RandomForestClassifier(max_depth=10, random_state=1)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Visualize the pipeline\n",
    "from sklearn import set_config\n",
    "\n",
    "set_config(display=\"diagram\")\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T12:02:41.035677Z",
     "start_time": "2023-07-20T12:02:40.993731Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get train data to train the classifier\n",
    "X_train = train_data.drop(model_target, axis=1)\n",
    "y_train = train_data[model_target]\n",
    "\n",
    "# Get validation data to validate the classifier\n",
    "X_test = test_data.drop(model_target, axis=1)\n",
    "y_test = test_data[model_target]\n",
    "\n",
    "# Get train data to train the classifier\n",
    "X_val = val_data.drop(model_target, axis=1)\n",
    "y_val = val_data[model_target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. <a name=\"3\">Train a Classifier</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "We use the pipeline with the desired data transformers, along with a Random Forest estimator for training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"31\">3.1. Model Training - Sklearn</a>\n",
    "\n",
    "We train the RandomForest classifier with __.fit()__ on our training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T12:02:41.450832Z",
     "start_time": "2023-07-20T12:02:41.369254Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fit the classifier to the train data\n",
    "clf = pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T12:02:41.875271Z",
     "start_time": "2023-07-20T12:02:41.838441Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's predict for the validation dataset\n",
    "y_val_pred = clf.predict(X_val)\n",
    "\n",
    "print(\"Model performance on the validation set:\")\n",
    "print(\"Validation accuracy:\", accuracy_score(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are concerned with model explainability in this notebook, so we will not perform any model tuning at this stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"32\">3.2. Model Training - PyTorch</a>\n",
    "\n",
    "As we want to compare explainability methods that rely on gradients and linear combinations, we will build a different type of model; a simple neural network (NN). For this, we need to cast our data as tensors first. Then we can set up the NN and train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T12:02:42.917254Z",
     "start_time": "2023-07-20T12:02:42.903814Z"
    }
   },
   "outputs": [],
   "source": [
    "# learn the encoding/transformation\n",
    "data_processor.fit(X_train)\n",
    "\n",
    "# convert to tensor - use fit transformer to encode features before converting to tensor\n",
    "X_train_tensor = torch.tensor(data_processor.transform(X_train)).float()\n",
    "y_train_tensor = torch.tensor(y_train.values).view(-1, 1).float()\n",
    "\n",
    "# repeat for validation set\n",
    "X_val_tensor = torch.tensor(data_processor.transform(X_val)).float()\n",
    "y_val_tensor = torch.tensor(y_val.values).view(-1, 1).float()\n",
    "\n",
    "# repeat for test set\n",
    "X_test_tensor = torch.tensor(data_processor.transform(X_test)).float()\n",
    "y_test_tensor = torch.tensor(y_test.values).view(-1, 1).float()\n",
    "\n",
    "# store tensor in TensorDataset and create DataLoader for iteration\n",
    "dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_iter = torch.utils.data.DataLoader(dataset, batch_size=20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T12:02:44.115634Z",
     "start_time": "2023-07-20T12:02:43.364097Z"
    }
   },
   "outputs": [],
   "source": [
    "# initialize NN hyperparameters\n",
    "num_epochs = 60\n",
    "learning_rate = 0.001\n",
    "\n",
    "# define architecture of NN\n",
    "size_hidden1 = 24\n",
    "size_hidden2 = 8\n",
    "\n",
    "torch.manual_seed(1)  # set seed for reproducibility.\n",
    "\n",
    "\n",
    "class LoanModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(49, size_hidden1)\n",
    "        self.activation_1 = nn.ReLU()\n",
    "        self.lin2 = nn.Linear(size_hidden1, size_hidden2)\n",
    "        self.activation_2 = nn.Sigmoid()\n",
    "        self.lin3 = nn.Linear(size_hidden2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.sigmoid(\n",
    "            self.lin3(self.activation_2(self.lin2(self.activation_1(self.lin1(input)))))\n",
    "        )\n",
    "\n",
    "    def train(net_model, num_epochs=num_epochs, verbose=True):\n",
    "        optimizer = torch.optim.Adam(net_model.parameters(), lr=learning_rate)\n",
    "        # define loss function\n",
    "        criterion = nn.BCELoss(reduction=\"none\")\n",
    "        # initialize empty lists to later track validation and training loss across epochs\n",
    "        val_losses = []\n",
    "        trn_losses = []\n",
    "        for epoch in range(1, num_epochs):\n",
    "            training_loss = 0.0\n",
    "            for inputs, labels in train_iter:\n",
    "                # zero parameter grads\n",
    "                optimizer.zero_grad()\n",
    "                # forward pass\n",
    "                outputs = net_model(inputs)\n",
    "                # calculate loss\n",
    "                loss = criterion(outputs, labels).sum()\n",
    "                # accumulating running loss\n",
    "                training_loss += loss.item()\n",
    "                # compute grads\n",
    "                loss.backward()\n",
    "                # updated weights based on computed gradients\n",
    "                optimizer.step()\n",
    "\n",
    "            # Get validation predictions\n",
    "            val_predictions = net_model(X_val_tensor)\n",
    "\n",
    "            # Calculate the validation loss\n",
    "            validation_loss = criterion(val_predictions, y_val_tensor).sum().item()\n",
    "\n",
    "            # Take the average losses\n",
    "            training_loss /= len(y_train_tensor)\n",
    "            validation_loss /= len(y_val_tensor)\n",
    "\n",
    "            # Append to list\n",
    "            trn_losses.append(training_loss)\n",
    "            val_losses.append(validation_loss)\n",
    "\n",
    "            if verbose == True:\n",
    "                # Print the losses every 15 epochs\n",
    "                if (epoch == 0) or ((epoch + 1) % 15 == 0):\n",
    "                    print(\n",
    "                        \"Epoch %s. Train_loss %f Validation_loss %f \"\n",
    "                        % (epoch, training_loss, validation_loss)\n",
    "                    )\n",
    "        if verbose == True:\n",
    "            plt.plot(trn_losses, label=\"Training Loss\")\n",
    "            plt.plot(val_losses, label=\"Validation Loss\")\n",
    "            plt.title(\"Loss values\")\n",
    "            plt.xlabel(\"Epoch\")\n",
    "            plt.ylabel(\"Loss\")\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "net = LoanModel()\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that after 15 epochs the model starts to overfit on the training data. Let's retrain the model with only  15 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = LoanModel()\n",
    "net.train(num_epochs=15, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T12:02:44.118857Z",
     "start_time": "2023-07-20T12:02:44.114841Z"
    }
   },
   "outputs": [],
   "source": [
    "# pass validation dataset through NN for predictions\n",
    "outputs = net(X_val_tensor)\n",
    "\n",
    "print(\"Model performance on the validation set:\")\n",
    "print(\n",
    "    \"Validation accuracy:\",\n",
    "    np.round(\n",
    "        accuracy_score(\n",
    "            # use torch round to convert probability values to classes (default round threshold is 0.5)\n",
    "            y_val_tensor.detach().numpy(),\n",
    "            torch.round(outputs).detach().numpy(),\n",
    "        ),\n",
    "        2,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. <a name=\"4\">Test the Classifier</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "Let's now evaluate the performance of the trained classifiers on the test dataset. We don't expect the performance to be different on the test dataset as there was no tuning conducted, hence the distribution of the test and validation data should be very similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"41\">4.1. Testing the Classifier - Sklearn</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T12:02:45.114890Z",
     "start_time": "2023-07-20T12:02:45.020943Z"
    }
   },
   "outputs": [],
   "source": [
    "# use the fitted model to make predictions on the test dataset\n",
    "test_predictions = clf.predict(X_test)\n",
    "\n",
    "print(\"Model performance on the test set:\")\n",
    "print(\"Test accuracy:\", accuracy_score(y_test, test_predictions))\n",
    "\n",
    "plt.style.use(\"seaborn-white\")\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "ConfusionMatrixDisplay.from_estimator(clf, X_test, y_test, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"42\">4.2. Testing the Classifier - PyTorch</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T12:02:46.042385Z",
     "start_time": "2023-07-20T12:02:45.937990Z"
    }
   },
   "outputs": [],
   "source": [
    "# pass test dataset through NN for predictions\n",
    "outputs = net(X_test_tensor)\n",
    "\n",
    "print(\"Model performance on the test set:\")\n",
    "print(\n",
    "    \"Test accuracy:\",\n",
    "    accuracy_score(\n",
    "        y_test_tensor.detach().numpy(), torch.round(outputs).detach().numpy()\n",
    "    ),\n",
    ")\n",
    "\n",
    "plt.style.use(\"seaborn-white\")\n",
    "fig, axs = plt.subplots(nrows=1, ncols=1, figsize=(4, 4))\n",
    "cmd = ConfusionMatrixDisplay(\n",
    "    confusion_matrix(\n",
    "        y_test_tensor.detach().numpy(), torch.round(outputs).detach().numpy()\n",
    "    )\n",
    ")\n",
    "cmd.plot(ax=axs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have predictions, we can look at some explanations for those predictions. Most explainers work with Sklearn or deep learning frameworks, such as PyTorch, as backend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. <a name=\"5\">Explanations</a>\n",
    "(<a href=\"#0\">Go to top</a>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"51\">5.1. SHAP</a>\n",
    "(<a href=\"#5\">Go to Explanations</a>)\n",
    "\n",
    "SHAP is an attributive explanation method; it quantifies the impact (called attribution) of each feature on the model prediction. SHAP values provide an answer to the question: \"What are the contributions of the input features toward the output prediction?\". SHAP (SHapley Additive exPlanations) is a game theoretic approach to explain the output of any machine learning model. It connects optimal credit allocation with local explanations using the classic Shapley values from game theory (see [paper](https://proceedings.neurips.cc/paper/2017/hash/8a20a8621978632d76c43dfd28b67767-Abstract.html) for details).\n",
    "\n",
    "SHAP iteratively “turns off” features and notes the marginal effect on the prediction. This is done for all possible permutations of features to compute a weighted average of the marginal effects. Because all permutations need to be considered SHAP has high computational complexity (some approximations/simplifications are implemented in the library to speed up the process). Let's have a look at SHAP values and plots for our dataset. To make the explanations more readable, we extract the features names (for encoded categorical columns) and create a small sample data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T12:02:50.242413Z",
     "start_time": "2023-07-20T12:02:50.234333Z"
    }
   },
   "outputs": [],
   "source": [
    "# extract feature names (this is required because onehot encoding created new columns)\n",
    "ft_names = (\n",
    "    numerical_features\n",
    "    + list(\n",
    "        data_processor.transformers_[1][1]\n",
    "        .named_steps[\"cat_encoder_nom\"]\n",
    "        .get_feature_names_out(categorical_features_nominal)\n",
    "    )\n",
    "    + list(\n",
    "        data_processor.transformers_[2][1]\n",
    "        .named_steps[\"cat_encoder_ord\"]\n",
    "        .get_feature_names_out(categorical_features_ordinal)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T12:02:50.779818Z",
     "start_time": "2023-07-20T12:02:50.765309Z"
    }
   },
   "outputs": [],
   "source": [
    "# create sample from X_test with the feature names attached\n",
    "X_sample = pd.DataFrame(data_processor.transform(X_test), columns=ft_names).copy(\n",
    "    deep=True\n",
    ")\n",
    "\n",
    "# needs to be 0 or 1 for binary classification; 1: credit complied, 0: not complied (risky customer)\n",
    "low_risk = 1\n",
    "high_risk = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have everything prepared, let's start using the SHAP explainer to get the SHAP values. Generally it is advisable to use the training dataset for the feature perturbation; to reduce computational run-time, we will proceed with the small sample dataset that we created in the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T12:02:54.534411Z",
     "start_time": "2023-07-20T12:02:54.349902Z"
    }
   },
   "outputs": [],
   "source": [
    "# create the explanations by passing in the model and the data, we can also use feature_names=ft_names\n",
    "explainer_shap = shap.Explainer(\n",
    "    clf[-1], feature_perturbation=\"tree_path_dependent\", seed=1\n",
    ")\n",
    "\n",
    "# extract SHAP values\n",
    "shap_values = explainer_shap(X_sample)\n",
    "\n",
    "# before proceeding further, we want to scale the numerical features back to the original values - careful as this will update the values in X_samples too\n",
    "shap_values.data[:, : len(numerical_features)] = (\n",
    "    clf[0]\n",
    "    .named_transformers_[\"numerical_processing\"]\n",
    "    .inverse_transform(shap_values.data[:, : len(numerical_features)])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a name=\"511\">5.1.1. Global SHAP explanations</a>\n",
    "(<a href=\"#51\">Go to SHAP</a>)\n",
    "\n",
    "Let's start with a global look at the model behavior first. The plot below sorts features by the sum of SHAP value magnitudes over all samples, and uses SHAP values to show the distribution of the impacts each feature has on the model output. The color represents the feature value (red high, blue low)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create beeswarm plot for global explanations\n",
    "shap.plots.beeswarm(shap_values[:, :, low_risk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create beeswarm plot for global explanations\n",
    "shap.plots.beeswarm(shap_values[:, :, low_risk])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a lot going on in this plot above, so let's look at a simpler visualization that uses the mean absolute value of the SHAP values for each feature to summarize importance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot that takes absolute SHAP values and averages across all data points\n",
    "shap.plots.bar(shap_values[0:, :, low_risk])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css\">\n",
    "<i class=\"fa fa-exclamation-circle\" style=\"color:red\"></i> Careful with this plot, it uses the absolute attribution values, so any directional information is lost! The absolute values are necessary to avoid cancelling of the positive/negative effects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a name=\"512\">5.1.2. Local SHAP explanations</a>\n",
    "(<a href=\"#51\">Go to SHAP</a>)\n",
    "\n",
    "We will now look at a local explanation created with SHAP. The explanation starts with a base value and will add & subtract SHAP values that push the model output from the base value (the average model output over the training dataset we passed) to the model output. Features pushing the prediction higher are shown in red, those pushing the prediction lower are in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T12:02:55.772342Z",
     "start_time": "2023-07-20T12:02:55.763529Z"
    }
   },
   "outputs": [],
   "source": [
    "# select a data point to analyze\n",
    "sample_to_explain = 34  # needs to be between 0 and length of data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T12:02:56.235764Z",
     "start_time": "2023-07-20T12:02:56.222825Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's first look at the predicted class for the data point we are interested in\n",
    "clf.predict_proba(X_test)[sample_to_explain : sample_to_explain + 1], clf.predict(\n",
    "    X_test\n",
    ")[sample_to_explain : sample_to_explain + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T12:02:56.860299Z",
     "start_time": "2023-07-20T12:02:56.633343Z"
    }
   },
   "outputs": [],
   "source": [
    "# create waterfall plot for being a credit risk for the data point in question (this individual has a low chance of not being a risk)\n",
    "shap.plots.waterfall(shap_values[sample_to_explain][:, high_risk])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expected value to have high credit risk in this dataset is approximately 0.3; for this particular instance the probability to have high risk is more than double that. We can use the visualization of the SHAP values above to better understand why this customer has such high risk. For example, we can see that this customer requested a very high contract duration, does not have any savings, has no checking account and also no significant property in their name (`property = 3` corresponds to \"car or other\", whereas `1` and `2` indicate the customer has real estate or significant savings in their name)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### EXERCISE\n",
    "<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/fontawesome.min.css\">\n",
    "<i class=\"fa-solid fa-book-open\"></i> Create a SHAP waterfall plot for the data point that is most certainly not a credit risk (you can rank by outcome probability). Write a short explanation for a hypothetical customer after looking at the waterfall plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T12:02:57.886591Z",
     "start_time": "2023-07-20T12:02:57.876283Z"
    }
   },
   "outputs": [],
   "source": [
    "##########################################################################################\n",
    "# Complete the code for the exercise below:\n",
    "\n",
    "\n",
    "##########################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When computing attributions for tree structured models such as random forests, the SHAP library uses an algorithm that estimates the Shapley values based on the tree model structure itself; to get a fast approximation of the expected model output conditional to the \"in-coalition\" features SHAP uses the leaf membership of training examples. In fact, there are other ways to compute feature attributions with SHAP too (beyond the tree-path dependent feature perturbation method).\n",
    "\n",
    "<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/fontawesome.min.css\">\n",
    "<i class=\"fa-solid fa-circle-exclamation\" style=\"color:red\"></i> Depending on how the feature attribution is calculated, you will obtain different SHAP values. The source of these differences stems from the way we treat \"out-of-coalition\" features. Let's see a few of these in the examples below. \n",
    "\n",
    "To try different explainers, we create a utility class, `AttributiveExplanation`.\n",
    "\n",
    "___\n",
    "For more details, have a look at \"[The many Shapley values for model explanation](https://arxiv.org/abs/1908.08474)\" (Sundararajan et al., 2019)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T12:03:02.316168Z",
     "start_time": "2023-07-20T12:03:02.305382Z"
    }
   },
   "outputs": [],
   "source": [
    "# define a utility class for storing attributions\n",
    "class AttributiveExplanation:\n",
    "    def __init__(self, shap_explainer, data):\n",
    "        self.explainer = shap_explainer\n",
    "        self.data = data\n",
    "        self.values = None\n",
    "\n",
    "    def compute(self):\n",
    "        self.values = self.explainer(self.data)\n",
    "        return self\n",
    "\n",
    "    def plot(self, data_point=sample_to_explain, show=True):\n",
    "        shap.plots.waterfall(self.values[data_point][:, high_risk], show=True)\n",
    "\n",
    "    def sv(self, data_point=sample_to_explain):\n",
    "        return self.values.values[data_point][:, high_risk]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tree-path dependent approach is “true to the data” because it avoids basing the computation of SHAP values on unrealistic data instances. It achieves this by constraining the sampling of “unknown” features (those not belonging to the coalition under study) to a range of values (i.e. partition of the feature space) allowed by the decision tree, effectively conditioning on the features that split prior nodes. With the `tree-path-dependent` setting, there is no background data required as the background distribution can be inferred from the structure of the model itself; this is useful when trying to understand a model without access to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T12:03:04.956979Z",
     "start_time": "2023-07-20T12:03:04.567029Z"
    }
   },
   "outputs": [],
   "source": [
    "# let's plot again the local attributions using the same explainer as before (clf[-1] is used to access the model)\n",
    "explainer_base = shap.Explainer(\n",
    "    clf[-1], feature_perturbation=\"tree_path_dependent\", seed=1\n",
    ")\n",
    "\n",
    "# compute SHAP values\n",
    "attributions_tree_path = AttributiveExplanation(explainer_base, X_sample).compute()\n",
    "\n",
    "# show output as plot\n",
    "attributions_tree_path.plot(data_point=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T12:03:07.054440Z",
     "start_time": "2023-07-20T12:03:05.182339Z"
    }
   },
   "outputs": [],
   "source": [
    "# now we look at another usage of the tree explainer that instead breaks the dependencies between features according to the rules dictated by causal inference - \"interventional\"\n",
    "explainer_interventional = shap.TreeExplainer(\n",
    "    clf[-1],\n",
    "    feature_perturbation=\"interventional\",\n",
    "    data=X_sample,\n",
    "    model_output=\"probability\",\n",
    ")\n",
    "\n",
    "# compute SHAP values\n",
    "attributions_interventional = AttributiveExplanation(\n",
    "    explainer_interventional, X_sample\n",
    ").compute()\n",
    "\n",
    "# show output as plot\n",
    "attributions_interventional.plot(data_point=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the explanations differ based on the perturbation method that is being used to generate the outputs. Let's have "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### EXERCISE\n",
    "<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/fontawesome.min.css\">\n",
    "<i class=\"fa-solid fa-book-open\"></i> Create another SHAP explanation by using a fixed value for the hidden features. To achieve this, you have to specify the <code>masker</code> parameter in the explainer which expects an array of values or a function. \n",
    "\n",
    "As simple first approach, you could calculate the mean across the dataset and pass that as array to the masker. Careful if you plan to use the <code>AttributiveExplanation</code> class; make sure to match the expected input format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################\n",
    "# Complete the code for the exercise below:\n",
    "\n",
    "\n",
    "##########################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice that different ways of treating out-of-coalition features results in largely different attributions. This is because the underlying _game_ on which you compute the Shapley value changes, and so does the interpretation of the explanations! Let's have a look at other limitations next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css\">\n",
    "<i class=\"fa fa-exclamation-circle\" style=\"color:red\"></i> SHAP (and other attribution methods) are also very sensitive to perturbations to the input. For instance, a small perturbation that does not affect the prediction may still alter the attribution value. Small changes in the data should not affect the predictions of the model or the explanation we get, yet the following example shows that small perturbations can indeed change the SHAP explanation (we will see that this happens for other explainability methods too). \n",
    "\n",
    "___\n",
    "More details about this can be found in the paper \"[On the Robustness of Interpretability Methods](https://arxiv.org/abs/1806.08049)\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sample from X_test with the feature names attached\n",
    "X_sample_per = X_sample.copy(deep=True)\n",
    "\n",
    "# define random noise\n",
    "mu, sigma = 0.05, 0.15\n",
    "\n",
    "# creating a noise with the same dimension as the dataset\n",
    "np.random.seed(seed=4)\n",
    "noise = np.random.normal(mu, sigma, [X_sample_per.shape[0], len(numerical_features)])\n",
    "\n",
    "# add noise to data\n",
    "X_sample_per.values[:, : len(numerical_features)] = (\n",
    "    X_sample_per.values[:, : len(numerical_features)] + noise\n",
    ")\n",
    "\n",
    "# Let's first look at the predicted class for the data point we are interested in\n",
    "clf[-1].predict_proba(X_sample_per)[sample_to_explain : sample_to_explain + 1], clf[\n",
    "    -1\n",
    "].predict(X_sample_per)[sample_to_explain : sample_to_explain + 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results match the output that we received before adding a tiny amount of random noise really well (as reminder, we previously obtained the following class probabilities: `array([[0.72354782, 0.27645218]])`). Clearly the model itself is not heavily influenced by the noise. Let's see what the perturbation did to the SHAP values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot again the local attributions using the same explainer as before\n",
    "explainer_perturbed = shap.Explainer(\n",
    "    clf[-1], feature_perturbation=\"tree_path_dependent\", seed=1\n",
    ")\n",
    "\n",
    "# compute SHAP values\n",
    "attributions_perturbed = AttributiveExplanation(\n",
    "    explainer_perturbed, X_sample_per\n",
    ").compute()\n",
    "\n",
    "# show output as plot\n",
    "ax1 = plt.subplot(211)\n",
    "attributions_perturbed.plot(show=True)\n",
    "\n",
    "# add margins\n",
    "ax1.margins(0.5)\n",
    "\n",
    "# show plot of undisturbed data for comparison\n",
    "ax2 = plt.subplot(212)\n",
    "shap.plots.waterfall(shap_values[sample_to_explain][:, high_risk], show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see that the small change in `amount` has resulted in change in the Shapley values. Let's have a look at one final limitation of SHAP values next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css\">\n",
    "<i class=\"fa fa-exclamation-circle\" style=\"color:red\"></i> The Shapley value is a way to distribute the contributions of each single features toward achieving a target prediction. As such it is a descriptive tool and can lack actionability. We shouldn't expect that changing the instance features using (any instantiations of) the Shapley value would yield to any predictable result. This is, e.g. in contrast with the gradient, which indicates the direction of local maximum increase of a function.\n",
    "\n",
    "Let's look at a toy example to see this clearly; this is inspired by [Problems with Shapley-value-based explanations as feature importance measures](https://arxiv.org/abs/2002.11097).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T12:03:13.073302Z",
     "start_time": "2023-07-20T12:03:13.071310Z"
    }
   },
   "outputs": [],
   "source": [
    "# a simple quadratic function with maximum in x = 1\n",
    "def f(x):\n",
    "    return 2 - (x - 1) ** 2\n",
    "\n",
    "\n",
    "# its gradient\n",
    "def grad(x):\n",
    "    return 2 - 2 * x\n",
    "\n",
    "\n",
    "# let's consider the scalar case for ease of visualization\n",
    "def shap_values_f(x, baseline=0.0):\n",
    "    return shap.Explainer(f, np.array([[baseline]]))(x).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T12:03:13.078984Z",
     "start_time": "2023-07-20T12:03:13.073749Z"
    }
   },
   "outputs": [],
   "source": [
    "# create sample datapoints\n",
    "xs = np.linspace(-1, 3)\n",
    "\n",
    "# compute SHAP values\n",
    "sh = shap_values_f(xs[:, None]).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T12:03:13.866712Z",
     "start_time": "2023-07-20T12:03:13.755713Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot function, gradient and Shapley values\n",
    "plt.plot(xs, f(xs), label=\"f(x) = 2 - (x - 1)^2\")\n",
    "plt.plot(xs, grad(xs), label=\"Gradient of f\")\n",
    "plt.plot(xs, sh, \".\", label=\"Shapley value with baseline = 0\")\n",
    "axes1 = (-3, 4), (0, 0)\n",
    "axes2 = (0, 0), (-3, 3)\n",
    "\n",
    "# plot intersecting lines\n",
    "plt.plot(*axes1, color=\"k\")\n",
    "plt.plot(*axes2, color=\"k\")\n",
    "\n",
    "# add legend and show plot\n",
    "plt.legend(loc=0)\n",
    "plt.xlim((-1, 3))\n",
    "plt.ylim((-2.5, 2.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At $x=1$ the Shapley value is 1. Since this is a positive number, one may think that by increasing the (single) feature then also the output should increase, but this is clearly not true. The gradient instead carries  this information. On the other hand, the Shapley value tells how we reach the model output starting from the baseline output (which in this case is $f(0) = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the feature value does not automatically increase the Shapley value. Because of this, we can say that SHAP lacks actionability which is one of the main desiderata of explainer methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a name=\"513\">5.1.3. Summary SHAP</a>\n",
    "(<a href=\"#51\">Go to SHAP</a>)\n",
    "\n",
    "Let's summarize this section:\n",
    "- We reviewed different choices of feature perturbation methods and checked Shapley values for robustness\n",
    "- We saw how SHAP values are not actionable as increase/decrease in feature values does not result in changes in the Shapley values.\n",
    "\n",
    "In the next section, we will review counterfactuals which are easy to comprehend, and can be used to offer a path of recourse to customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"52\">5.2. DiCE Counterfactuals</a>\n",
    "(<a href=\"#5\">Go to Explanations</a>)\n",
    "\n",
    "\n",
    "**Counterfactual Explanations (CEs)** are imaginary versions of model inputs that receive a different prediction than the original input. To be actionable, counterfactuals should be as similar as possible to the original input in terms of feature values. To find a counterfactual, the difference, $d$,  between the original input, $x$, and the imaginary input, $x_c$, are calculated. Obviously there are many possible imaginary inputs, so the goal is to find the one example, $x_c$, that is closest to the original in terms of feature values, yet has a different outcome:\n",
    "\n",
    "> argmin $d(x, x_C) \\; s.t. \\; f(x_c) \\neq y$\n",
    "\n",
    "To be practical, the feature values should be feasible and ideally, a counterfactual should change as few features as possible. \n",
    "\n",
    "Below, we will take an input that was classified by our models as credit risk. We will generate CEs -- counterfactual versions of this input -- showing the changes required so that the classifier prediction changes to no risk. Generating counterfactual explanations in code is a simple three-step process: initialize dataset, point to model and then invoke DiCE to generate counterfactual examples for any input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T17:50:17.501729Z",
     "start_time": "2023-07-18T17:50:17.482310Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset for training an ML model\n",
    "d = dice_ml.Data(\n",
    "    dataframe=train_data,\n",
    "    continuous_features=numerical_features + categorical_features_ordinal,\n",
    "    outcome_name=model_target,\n",
    "    type_and_precision=\"int\",\n",
    ")\n",
    "\n",
    "# Using sklearn backend\n",
    "m = dice_ml.Model(model=clf, backend=\"sklearn\")\n",
    "\n",
    "# Using random method for generating CFs\n",
    "exp = dice_ml.Dice(d, m, method=\"random\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a name=\"521\">5.2.1. Local counterfactual explanations</a>\n",
    "(<a href=\"#52\">Go to CE</a>)\n",
    "\n",
    "DiCE implements counterfactual (CF) explanations that provide this information by showing feature-perturbed versions of the same person who would have received the loan, e.g., you would have received the loan if your income was higher by 10,000 USD. In other words, it provides \"what-if\" explanations for model output and can be a useful complement to other explanation methods, both for end-users and model developers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T17:50:18.553502Z",
     "start_time": "2023-07-18T17:50:18.443294Z"
    }
   },
   "outputs": [],
   "source": [
    "e1 = exp.generate_counterfactuals(\n",
    "    X_test[sample_to_explain : sample_to_explain + 1],\n",
    "    total_CFs=4,\n",
    "    desired_class=1,\n",
    "    random_seed=4,\n",
    ")\n",
    "e1.visualize_as_dataframe(show_only_changes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css\">\n",
    "<i class=\"fa fa-exclamation-circle\" style=\"color:red\"></i> Not all counterfactual explanations may be feasible for a customer. In general, counterfactuals closer to an individuals' profile will be more feasible. Diversity is also important to help an individual choose between multiple possible options. DiCE provides tunable parameters for diversity and proximity to generate different kinds of explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T17:50:21.249724Z",
     "start_time": "2023-07-18T17:50:21.109725Z"
    }
   },
   "outputs": [],
   "source": [
    "e2 = exp.generate_counterfactuals(\n",
    "    X_test[sample_to_explain : sample_to_explain + 1],\n",
    "    total_CFs=4,\n",
    "    desired_class=\"opposite\",\n",
    "    proximity_weight=1.5,\n",
    "    diversity_weight=2.0,\n",
    "    random_seed=2,\n",
    ")\n",
    "\n",
    "e2.visualize_as_dataframe(show_only_changes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css\">\n",
    "<i class=\"fa fa-exclamation-circle\" style=\"color:red\"></i> Some features such as one's age or gender, are impossible to change for a credit loan applicant. Therefore, DiCE also allows inputting a list of features to vary.\n",
    "\n",
    "DiCE also supports simple constraints on features that reflect practical constraints (e.g., housing is 'rent' using the `permitted_range` parameter). Banks could not expect someone to buy a house to change their housing status from 'rent' to 'own' so it makes sense to restrict the permitted range. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vary_features = [\"amount\", \"duration\"]\n",
    "\n",
    "# Restricting housing to be either {'rent'}\n",
    "e3 = exp.generate_counterfactuals(\n",
    "    X_test[sample_to_explain : sample_to_explain + 1],\n",
    "    desired_class=\"opposite\",\n",
    "    total_CFs=4,\n",
    "    features_to_vary=vary_features,\n",
    "    permitted_range={\"amount\": [200, 6000]},\n",
    "    random_seed=5,\n",
    ")\n",
    "\n",
    "e3.visualize_as_dataframe(show_only_changes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a shorter credit duration as counterfactual, so this is something that the applicant could indeed aspire to pursue. We can also observe that the permitted range was considered as defined (there are no counterfactuals with amounts higher than the specified 6000)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### EXERCISE\n",
    "\n",
    "<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/fontawesome.min.css\">\n",
    "<i class=\"fa-solid fa-book-open\"></i> Create three CF explanations that restricts the permitted <code>duration</code> to be between 10 and 60 (inclusive) and <code>employment_duration</code> to values greater than 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################\n",
    "# Complete the code for the exercise below:\n",
    "\n",
    "\n",
    "##########################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While setting permitted ranges manually can be helpful, it can also be very tedious to do manually. Rather than testing all possible value combinations, we can simply plot the boundary of the counterfactuals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_instance = X_test[sample_to_explain : sample_to_explain + 1]\n",
    "query_ce_df = e3.cf_examples_list[0].final_cfs_df\n",
    "\n",
    "plot_boundary_with_ce(\n",
    "    query_instance,\n",
    "    query_ce_df,\n",
    "    clf,\n",
    "    X_train,\n",
    "    vary_features,\n",
    "    categorical_features,\n",
    "    color_mapping={0: \"Red\", 1: \"Green\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### EXERCISE\n",
    "\n",
    "<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/fontawesome.min.css\">\n",
    "<i class=\"fa-solid fa-book-open\"></i> Recreate the plot above but this time use 'job' and 'duration'. What is the maximum accepted duration that will still give a positive outcome for the customer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################\n",
    "# Complete the code for the exercise below:\n",
    "\n",
    "\n",
    "##########################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to create counterfactuals when the model is a deep neural network; the below code examples shows an implementation. More details about the method to find explanations can be found in \"[Explaining Machine Learning Classifiers through Diverse Counterfactual Explanations](https://arxiv.org/abs/1905.07697)\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize dataset; the PyTorch model in this notebok expects the transformed dataset as input, so we need to recreate this here\n",
    "d_pyt = dice_ml.Data(\n",
    "    dataframe=pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(data_processor.transform(X_test), columns=ft_names),\n",
    "            pd.DataFrame(y_test.values, columns=[model_target]),\n",
    "        ],\n",
    "        1,\n",
    "    ),\n",
    "    continuous_features=numerical_features + categorical_features_ordinal,\n",
    "    outcome_name=model_target,\n",
    "    type_and_precision=\"int\",\n",
    ")\n",
    "\n",
    "# get sample datapoint transformed\n",
    "x_transformed = pd.DataFrame(\n",
    "    data_processor.transform(X_test[sample_to_explain : sample_to_explain + 1]),\n",
    "    columns=ft_names,\n",
    ")\n",
    "\n",
    "# use PyTorch backend\n",
    "m_pyt = dice_ml.Model(model=net, backend=\"PYT\")\n",
    "\n",
    "# initialize explainer\n",
    "exp_pyt = dice_ml.Dice(d_pyt, m_pyt, method=\"gradient\")\n",
    "\n",
    "# pass in instance and create counterfactuals\n",
    "e_pyt = exp_pyt.generate_counterfactuals(\n",
    "    query_instances=x_transformed,\n",
    "    desired_class=\"opposite\",\n",
    "    total_CFs=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse transformation for numerical features\n",
    "x_num = data_processor.named_transformers_[\"numerical_processing\"].inverse_transform(\n",
    "    x_transformed[numerical_features]\n",
    ")\n",
    "\n",
    "# update values in df\n",
    "x_transformed.loc[:, numerical_features] = x_num.round(-1)\n",
    "x_transformed.loc[:, model_target] = y_test[\n",
    "    sample_to_explain : sample_to_explain + 1\n",
    "].values\n",
    "\n",
    "# show df\n",
    "x_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract counterfactuals to dataframe\n",
    "e_pyt_df = e_pyt.cf_examples_list[0].final_cfs_df.copy(deep=True)\n",
    "\n",
    "# inverse transformation numerical features\n",
    "e_pyt_num_fts = data_processor.named_transformers_[\n",
    "    \"numerical_processing\"\n",
    "].inverse_transform(e_pyt_df[numerical_features])\n",
    "\n",
    "# update values in counterfactal df\n",
    "e_pyt_df.loc[:, numerical_features] = e_pyt_num_fts.round(-1)\n",
    "\n",
    "# show counterfactuals\n",
    "e_pyt_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've seen different ways to create local explanations using counterfactuals, we can move on to the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a name=\"522\">5.2.2. Global counterfactual explanations</a>\n",
    "(<a href=\"#52\">Go to CE</a>)\n",
    "\n",
    "It is also possible to look at global feature importance with counterfactuals. Intuitively, a feature that is changed more often to generate a counterfactual is an important feature. Hence, it is possible to use summaries of counterfactual examples to estimate importance of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_ce = exp.global_feature_importance(\n",
    "    X_test[0:10], total_CFs=10, posthoc_sparsity_param=None\n",
    ")\n",
    "print(global_ce.summary_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a name=\"523\">5.2.3. Summary CE</a>\n",
    "(<a href=\"#52\">Go to CE</a>)\n",
    "\n",
    "Let's summarise some of the challenges we encountered when working with counterfactuals.\n",
    "\n",
    "<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css\">\n",
    "<i class=\"fa fa-exclamation-circle\" style=\"color:red\"></i> The first first challenge is how to define \"closeness\" between the original data point and the counterfactual. It turns out that this is actually not trivial as features can vary on different scales, and loss can therefore vary non-linearly with the feature value. For instance, `amount` in our dataset can vary in the thousands but `duration` only varies in the tens. When working with counterfactuals it can be helpful to consult a domain expert to provide a domain-specific distance functions.\n",
    "<br>\n",
    "<br>\n",
    "<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css\">\n",
    "<i class=\"fa fa-exclamation-circle\" style=\"color:red\"></i> Furthermore, to obtain counterfactuals an optimization problem has to solved which can be computationally challenging, especially when the dataset contains categorical features which turn the problem into a combinatorial optimization problem. \n",
    "<br>\n",
    "<br>\n",
    "<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css\">\n",
    "<i class=\"fa fa-exclamation-circle\" style=\"color:red\"></i> Finally, features highlighted in counterfactuals may not always have a large attribution. This can happen when the majority of the datapoints in the dataset has the same (or similar) feature value. For example, in our dataset the `number_credits` feature is the same for almost all loan applicants. This will lead to attribution methods such as SHAP to not attribute much value to it. However, decreasing the number of credits (paying off other debtors) may very well be a valid recourse that would make the applicant credit worthy.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Let's summarize this section:\n",
    "- We implemented counterfactuals for different model backends (sklearn & PyTorch) and visualized the results\n",
    "- We reviewed different settings for creating counterfactuals that consider proximity and feasibility of the resulting counterfactuals\n",
    "\n",
    "In the next section, we will review integrated gradients as a method that works very well for various deep learning models and is a computationally very efficient method to create explanations (in particular for non-tabular data).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"53\">5.3. Integrated Gradients (IG)</a>\n",
    "(<a href=\"#5\">Go to Explanations</a>)\n",
    "\n",
    "Gradients are useful way to measure the importance of features in parametric models (specifically, the model has to be differentiable to be able to obtain gradients in the first place). Gradients describe the local slope of an arbitrary function, $f(x)$ (here: the model), and allow us to quantify whether taking a small step in either direction on the function has a small or large effect on the result. In the context of explainability, we want to understand if a change in the input feature has an impact on the output (prediction), so we calculate the gradient of the input with respect to the output. \n",
    "\n",
    "\n",
    "<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css\">\n",
    "<i class=\"fa fa-exclamation-circle\" style=\"color:red\"></i> However, simple gradient based explanations can be noisy and suffer from a saturation problem: whenever the model is saturated, the gradient will be 0 (see \"<a href=\"https://arxiv.org/abs/1704.02685\">Learning Important Features Through Propagating Activation Differences</a>\" for details).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### <a name=\"531\">5.3.1. IG method</a>\n",
    "(<a href=\"#53\">Go to IG</a>)\n",
    "\n",
    "Integrated Gradients (IG) is a technique that bypasses the saturation problem by attributing a differentiable model's prediction to its base features. IG creates a straight line path in the feature space, from a given input data point to a certain baseline input (e.g., all-zero baseline), and integrates the gradient of the output (prediction) with respect to input features along this path.\n",
    "\n",
    "Gradient-based explanation methods try to explain a given prediction by using the gradient of (i.e. change in) the output with respect to the input features. Computing (integrated) gradients is well supported in most machine learning frameworks which makes gradient-based explanations a sensible choice when working with neural networks in particular. IG will also work for different data modalities (e.g., image data - see `Explainability_ImageData.ipynb`) and is computationally efficient compared to other methods as there are no permutations or large amounts of repeat calculations required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the IG method\n",
    "ig = IntegratedGradients(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper method to print importances and visualize distribution\n",
    "def visualize_importances(\n",
    "    feature_names,\n",
    "    importances,\n",
    "    verbose=False,\n",
    "    title=\"Average Feature Importances\",\n",
    "    plot=True,\n",
    "    axis_title=\"Features\",\n",
    "):\n",
    "    if verbose == True:\n",
    "        print(title)\n",
    "        for i in range(len(feature_names)):\n",
    "            print(feature_names[i], \": \", \"%.3f\" % (importances[i]))\n",
    "    x_pos = np.arange(len(feature_names))\n",
    "    if plot:\n",
    "        plt.figure(figsize=(20, 6))\n",
    "        plt.bar(x_pos, importances, align=\"center\")\n",
    "        plt.xticks(x_pos, feature_names, wrap=False, rotation=90)\n",
    "        plt.xlabel(axis_title)\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IG expects a baseline; when baseline is not provided, Captum uses a zero scalar corresponding to each input tensor. For a network with multiple possible outputs, a target index must also be provided, defining the index of the output for which gradients are computed. For this example, we don't need to provide a target as there is no target index necessary when the model provides a scalar value per example. \n",
    "\n",
    "The returned values of the attribute method are the attributions, which match the size of the given inputs, and delta, which approximates the error between the approximated integral and true integral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig_attr_train = ig.attribute(X_train_tensor.requires_grad_(), n_steps=50)\n",
    "visualize_importances(ft_names, np.mean(ig_attr_train.detach().numpy(), axis=0), False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that `installment_rate` and `employment_duration` have the highest negative and positive average feature importance. Interestingly, `employment_duration` was not a feature that was considered important by other explainability methods so far. Employment duration is positively correlated with the output, whereas installment_rate is negatively correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### EXERCISE\n",
    "\n",
    "<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/fontawesome.min.css\">\n",
    "<i class=\"fa-solid fa-book-open\"></i> Recreate the plot above but this time use <code>InputXGradient</code>. \n",
    "\n",
    "Make sure to import the explainer first with `from captum.attr import InputXGradient`. More details about the method can be found [here](https://captum.ai/api/input_x_gradient.html). How do the results differ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################\n",
    "# Complete the code for the exercise below:\n",
    "\n",
    "\n",
    "##########################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a name=\"532\">5.3.2. IG method</a>\n",
    "(<a href=\"#53\">Go to IG</a>)\n",
    "\n",
    "Let's summarize this section:\n",
    "- We discussed the difference between 'vanilla' gradient-based methods and IG\n",
    "- We implemented IG for the custom NN and created a visualization to show the average feature importances\n",
    "\n",
    "In the next section, we will review one final method that tries to extract explanations from the dataset that was used to train the model itself by finding influential training instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"54\">5.4. Deletion Diagnostic</a>\n",
    "(<a href=\"#5\">Go to Explanations</a>)\n",
    "\n",
    "The key idea behind influential instances is to trace model parameters and predictions back to where it all began: the training data. A (parametric) machine learning algorithm is a function that takes training data consisting of features, $X$, and target, $y$, and learns optimal parameters that minimize the loss between true and predicted value. Therefore, a first step for debugging is to see how the model parameters or the predictions would change if we removed instances from the training data in the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T12:02:47.784402Z",
     "start_time": "2023-07-20T12:02:47.776286Z"
    }
   },
   "outputs": [],
   "source": [
    "def deletion_diagnostic(X, y, model):\n",
    "    \"\"\"\n",
    "    Function to iteratively train a model on subset of data points to find influential instances.\n",
    "    :param X: pd.DataFrame with features\n",
    "    :param y: array with target\n",
    "    :param model: model pipeline\n",
    "\n",
    "    :return: list of class probability differences\n",
    "    \"\"\"\n",
    "    # reset indices to simplify loop\n",
    "    X = X.reset_index(drop=True).copy(deep=True)\n",
    "    y = y.reset_index(drop=True).copy(deep=True)\n",
    "    # use original model to make predictions - keep good credit (0)\n",
    "    y_pred = model.predict_proba(X)[:, [0]]\n",
    "    # initialize list to store difference between output probabilities\n",
    "    influence_diff = []\n",
    "    # loop through dataframe and iteratively drop one data point\n",
    "    for i in tqdm(range(0, len(X))):\n",
    "        subset_X = X.drop(index=i)\n",
    "        subset_y = y.drop(index=i)\n",
    "        # fit model on subset\n",
    "        m = model.fit(subset_X, subset_y)\n",
    "        # get prediction on subset\n",
    "        subset_y_pred = m.predict_proba(subset_X)[:, [0]]\n",
    "        # fill current idx value with nan\n",
    "        subset_y_pred = np.insert(subset_y_pred, i, np.nan)\n",
    "        # take difference between original and subset value\n",
    "        influence_diff.append(y_pred.reshape(-1) - subset_y_pred.reshape(-1))\n",
    "    return np.array(influence_diff)\n",
    "\n",
    "\n",
    "diff = deletion_diagnostic(X_train, y_train, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T12:02:48.544358Z",
     "start_time": "2023-07-20T12:02:48.527778Z"
    }
   },
   "outputs": [],
   "source": [
    "# rows correspond to iteration of training (which in turns correspond to running the learning algorithm on all the dataset minus one example), columns are the probability differences for a given data point\n",
    "influence_df = pd.DataFrame(np.asmatrix(diff))\n",
    "\n",
    "# get mean influence value per data point, absolute value first as difference can be pos and neg - avoid cancelling out\n",
    "influence_vals = np.abs(influence_df).mean(\n",
    "    skipna=True, axis=0\n",
    ")  # lf todo, do you have a reference for this procedure? or .... why don't we look at the validation error instead?\n",
    "\n",
    "# sort from highest diff to lowest\n",
    "sorted_influential = influence_vals.sort_values(ascending=False)\n",
    "\n",
    "# look at most influential instances\n",
    "print(sorted_influential[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The influential instances are the first ones that should be checked for errors, because each error in them strongly influences the model predictions. For example, we could try re-training the model without those instances and check the performance. For more suggestions on how to interpret and work with influential instances have a look at [Koh and Liang](https://arxiv.org/pdf/1703.04730.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thank you for participating!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kdd",
   "language": "python",
   "name": "kdd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
